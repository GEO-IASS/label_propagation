{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import sys\n",
    "\n",
    "#from pylab import *\n",
    "#%pylab inline\n",
    "#pylab.rcParams['figure.figsize'] = (50, 10)\n",
    "#np.set_printoptions(precision = 17)\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "import IPython.display\n",
    "\n",
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# caffe layers\n",
    "caffe_root = '/users/vijay.kumar/caffe/'\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "import caffe\n",
    "from caffe import layers as L\n",
    "\n",
    "# enable gpu\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': (1,3,224,224)})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "#transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR # not required.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proto_file = '/users/vijay.kumar/code/person_recognition/models/new/vgg_face_caffe/VGG_FACE_deploy.prototxt'\n",
    "weights = '/users/vijay.kumar/code/person_recognition/models/new/vgg_face_caffe/VGG_FACE.caffemodel'\n",
    "net = caffe.Net(proto_file, weights, caffe.TEST)\n",
    "net.forward()\n",
    "avgImg = [129.1863,104.7624,93.5940]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:31: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931\n",
      "931\n",
      "931\n",
      "931\n",
      "931\n",
      "931\n",
      "931\n",
      "931\n",
      "931\n"
     ]
    }
   ],
   "source": [
    "album_gt_path = 'data/G-album/GallagherDatasetGT.txt'\n",
    "image_dir = 'data/G-album/data/'\n",
    "count = 0\n",
    "num_examples = sum(1 for line in open(album_gt_path))\n",
    "features = np.zeros((num_examples, 4096))\n",
    "with open(album_gt_path) as f:\n",
    "    for line in f:        \n",
    "        line_split = line.strip().split('\\t')\n",
    "        img_name = line_split[0]\n",
    "        label = line_split[5]\n",
    "        image = cv2.imread(image_dir + img_name)     ## NOTE USING OPENCV TO READ.. # BGR Format\n",
    "        x1 = int(line_split[1])\n",
    "        y1 = int(line_split[2])\n",
    "        x2 = int(line_split[3])\n",
    "        y2 = int(line_split[4])\n",
    "        \n",
    "        new_x1 = x1 - 0.5*abs(x1-x2)\n",
    "        if new_x1 < 0: \n",
    "            new_x1 = 0\n",
    "        \n",
    "        new_x2 = x2 + 0.5*abs(x1-x2)\n",
    "        if new_x2 > image.shape[1]:\n",
    "            new_x2 = image.shape[1]\n",
    "        \n",
    "        new_y1 = y1 - 0.5*abs(x1-x2)\n",
    "        if new_y1 < 0:\n",
    "            new_y1 = 0\n",
    "        f_w = new_x2 - new_x1\n",
    "        f_h = f_w\n",
    "        \n",
    "        face = image[new_y1:new_y1+f_h, new_x1:new_x1+f_w,:]\n",
    "        face[0] = face[0] - avgImg[2]\n",
    "        face[1] = face[1] - avgImg[1]\n",
    "        face[2] = face[2] - avgImg[0]\n",
    "    \n",
    "        #showarray(face)\n",
    "        transformed_image = transformer.preprocess('data', face)                \n",
    "        net.blobs['data'].data[0, ...] = transformed_image\n",
    "        net.forward(start='conv1_1')\n",
    "        features[count] = net.blobs['fc7'].data\n",
    "        count = count + 1        \n",
    "        \n",
    "        if count%100 == 0:\n",
    "            print count\n",
    "np.savez('/home/vijay.kumar/semi-supervised/galbum_feas',features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
